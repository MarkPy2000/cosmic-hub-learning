<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Everything You Need to Know About HTTP</title>
    <link rel="stylesheet" href="http.css">
</head>
<body>
    <header class="space-header">
        <h1>Everything You Need to Know About HTTP</h1>
        <p>February 16, 2021</p>
    </header>
    <main>
        <section class="section-content">
            <h2>What is HTTP?</h2>
            <p>First things first, what is HTTP? HTTP is a TCP/IP-based application layer communication protocol that standardizes how clients and servers communicate with each other. It defines how content is requested and transmitted across the internet. By application layer protocol, I mean that it’s simply an abstraction layer that standardizes how hosts (clients and servers) communicate. HTTP itself depends on TCP/IP to get requests and responses between the client and server. By default, TCP port 80 is used, but other ports can also be used. HTTPS, however, uses port 443.</p>
        </section>

        <section class="section-content">
            <h2>HTTP/0.9 - The One Liner (1991)</h2>
            <p>The first documented version of HTTP was HTTP/0.9 which was put forward in 1991. It was the simplest protocol ever; having a single method called GET. If a client had to access some webpage on the server, it would have made the simple request like below:</p>
            <pre><code>GET /</code></pre>
            <p>And the response from server would have looked as follows:</p>
            <pre><code>(response body)
(connection closed)</code></pre>
            <ul>
                <li>GET was the only allowed method</li>
                <li>Response had to be HTML</li>
            </ul>
            <p>As you can see, the protocol really had nothing more than being a stepping stone for what was to come.</p>
        </section>

        <section class="section-content">
            <h2>HTTP/1.0 - 1996</h2>
            <p>In 1996, the next version of HTTP i.e. HTTP/1.0 evolved that vastly improved over the original version.</p>
            <p>Unlike HTTP/0.9 which was only designed for HTML response, HTTP/1.0 could now deal with other response formats i.e. images, video files, plain text or any other content type as well. It added more methods (i.e. POST and HEAD), request/response formats got changed, HTTP headers got added to both the request and responses, status codes were added to identify the response, character set support was introduced, multi-part types, authorization, caching, content encoding and more was included.</p>
            <p>Here is how a sample HTTP/1.0 request and response might have looked like:</p>
            <pre><code>GET / HTTP/1.0
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10.5)
Accept: */*</code></pre>
            <p>Example response to the request above may have looked like below:</p>
            <pre><code>HTTP/1.0 200 OK
Content-Type: text/html
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 05 August 1996 15:55:28 GMT
Server: Apache 0.84
(response body)
(connection closed)</code></pre>
            <p>In the very beginning of the response there is HTTP/1.0 (HTTP followed by the version number), then there is the status code 200 followed by the reason phrase (or description of the status code, if you will).</p>
            <p>In this newer version, request and response headers were still kept as ASCII encoded, but the response body could have been of any type i.e. image, video, HTML, plain text or any other content type. So, now that server could send any content type to the client; not so long after the introduction, the term “Hyper Text” in HTTP became misnomer. HTTP or Hypermedia Transfer Protocol might have made more sense but, I guess, we are stuck with the name for life.</p>
            <p>One of the major drawbacks of HTTP/1.0 were you couldn't have multiple requests per connection. That is, whenever a client will need something from the server, it will have to open a new TCP connection and after that single request has been fulfilled, connection will be closed. And for any next requirement, it will have to be on a new connection. Why is it bad? Well, let's assume that you visit a webpage having 10 images, 5 stylesheets and 5 javascript files, totaling to 20 items that needs to be fetched when request to that webpage is made. Since the server closes the connection as soon as the request has been fulfilled, there will be a series of 20 separate connections where each of the items will be served one by one on their separate connections. This large number of connections results in a serious performance hit as requiring a new TCP connection imposes a significant performance penalty because of three-way handshake followed by slow-start.</p>
            <h3>Three-way Handshake</h3>
            <p>Three-way handshake in its simplest form is that all the TCP connections begin with a three-way handshake in which the client and the server share a series of packets before starting to share the application data.</p>
            <ul>
                <li>SYN - Client picks up a random number, let’s say x, and sends a SYN packet</li>
                <li>SYN ACK - Server acknowledges the request by sending an ACK packet back to the client which is made up of a random number, let’s say y picked up by server and the number x+1 where x is the number that was sent by the client</li>
                <li>ACK - Client increments the number y received from the server and sends an ACK packet back with the number y+1</li>
            </ul>
            <p>Once the three-way handshake is completed, the data sharing between the client and server may begin. It should be noted that the client may start sending the application data as soon as it dispatches the last ACK packet but the server will still have to wait for the ACK packet to be received in order to fulfill the request.</p>
            <p>However, some implementations of HTTP/1.0 tried to overcome this issue by introducing a new header called Connection: keep-alive which was meant to tell the server “Hey server, do not close this connection, I need it again”. But still, it wasn’t that widely supported and the problem still persisted.</p>
            <p>Apart from being connectionless, HTTP also is a stateless protocol i.e. server doesn’t maintain the information about the client and so each of the requests has to have the information necessary for the server to fulfill the request on its own without any association with any old requests. And so this adds fuel to the fire i.e. apart from the large number of connections that the client has to open, it also has to send some redundant data on the wire causing increased bandwidth usage.</p>
        </section>

        <section class="section-content">
            <h2>HTTP/1.1 - 1999</h2>
            <p>After merely 3 years of HTTP/1.0, the next version i.e. HTTP/1.1 was released in 1999; which made a lot of improvements over its predecessor. The major improvements over HTTP/1.0 included:</p>
            <ul>
                <li>New HTTP methods were added, which introduced PUT, PATCH, OPTIONS, DELETE</li>
                <li>Hostname Identification: In HTTP/1.0 Host header wasn’t required but HTTP/1.1 made it required.</li>
                <li>Persistent Connections: As discussed above, in HTTP/1.0 there was only one request per connection and the connection was closed as soon as the request was fulfilled which resulted in acute performance hit and latency problems. HTTP/1.1 introduced persistent connections i.e. connections weren't closed by default and were kept open which allowed multiple sequential requests. To close the connections, the header Connection: close had to be available on the request. Clients usually send this header in the last request to safely close the connection.</li>
                <li>Pipelining: It also introduced the support for pipelining, where the client could send multiple requests to the server without waiting for the response from server on the same connection and server had to send the response in the same sequence in which requests were received. But how does the client know that this is the point where first response download completes and the content for next response starts, you may ask! Well, to solve this, there must be Content-Length header present which clients can use to identify where the response ends and it can start waiting for the next response.</li>
                <li>Chunked Transfers: In case of dynamic content generation, servers may not know the content length at the beginning. In such cases, servers could use chunked transfer encoding where content is sent in chunks and a zero-length chunk at the end indicating that the response transmission is complete. So, the client, upon receiving a chunked response, may start rendering the content as soon as it starts receiving the chunks and doesn't have to wait till the end of whole transmission.</li>
                <li>Cache Management: HTTP/1.0 had some limited caching mechanisms but HTTP/1.1 greatly improved upon it and introduced new headers i.e. ETag, If-Match, If-None-Match, If-Modified-Since, If-Unmodified-Since, Cache-Control which allowed fine-grained cache management.</li>
                <li>Authentication: HTTP/1.1 also added a new authentication method (Basic Authentication) and an improved Digest Authentication</li>
            </ul>
        </section>

        <section class="section-content">
            <h2>HTTP/2 - 2015</h2>
            <p>HTTP/2 was introduced in 2015 to bring further performance improvements over its predecessor. Major improvements included:</p>
            <ul>
                <li>Multiplexing: HTTP/2 allowed multiple requests and responses to be sent simultaneously over a single TCP connection which removed the need for opening multiple connections.</li>
                <li>Binary Protocol: Unlike HTTP/1.x which was text-based, HTTP/2 is binary protocol which made parsing more efficient and reduced errors.</li>
                <li>Header Compression: HTTP/2 introduced header compression which reduced overheads caused by headers being sent multiple times in every request.</li>
                <li>Stream Prioritization: HTTP/2 allowed clients to assign priority levels to different requests so that important requests could be fulfilled first.</li>
                <li>Server Push: HTTP/2 allowed servers to push resources to the client before they are requested, improving load times.</li>
            </ul>
        </section>

        <section class="section-content">
            <h2>HTTP/3 - 2022</h2>
            <p>HTTP/3 was introduced in 2022 and is based on QUIC (Quick UDP Internet Connections) protocol. Major improvements included:</p>
            <ul>
                <li>Built on QUIC: HTTP/3 uses QUIC as its transport layer which is built on UDP rather than TCP. This allows for faster connection establishment and better handling of packet loss.</li>
                <li>Improved Multiplexing: HTTP/3 further improves multiplexing by eliminating head-of-line blocking problems seen in HTTP/2.</li>
                <li>Faster Connection Establishment: QUIC allows for faster connection establishment and better performance in poor network conditions.</li>
            </ul>
        </section>
    </main>
    <footer>
        <p>© 2024 Everything You Need to Know About HTTP</p>
    </footer>
    <div class="stars"></div>

    <script src="http.js"></script>

    <script>
        // Create stars dynamically
        const starsContainer = document.querySelector('.stars');
        for (let i = 0; i < 100; i++) {
            const star = document.createElement('div');
            star.classList.add('star');
            star.style.top = `${Math.random() * 100}vh`;
            star.style.left = `${Math.random() * 100}vw`;
            star.style.animationDuration = `${Math.random() * 5 + 5}s`;
            starsContainer.appendChild(star);
        }
    </script>
</body>
</html>
